{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":228180,"sourceType":"datasetVersion","datasetId":14872}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn import datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-24T05:09:29.494999Z","iopub.execute_input":"2024-08-24T05:09:29.495685Z","iopub.status.idle":"2024-08-24T05:09:30.109686Z","shell.execute_reply.started":"2024-08-24T05:09:29.495635Z","shell.execute_reply":"2024-08-24T05:09:30.108898Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"iris = datasets.load_iris()\niris","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:13:00.734608Z","iopub.execute_input":"2024-08-24T05:13:00.735373Z","iopub.status.idle":"2024-08-24T05:13:00.751993Z","shell.execute_reply.started":"2024-08-24T05:13:00.735334Z","shell.execute_reply":"2024-08-24T05:13:00.751049Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'data': array([[5.1, 3.5, 1.4, 0.2],\n        [4.9, 3. , 1.4, 0.2],\n        [4.7, 3.2, 1.3, 0.2],\n        [4.6, 3.1, 1.5, 0.2],\n        [5. , 3.6, 1.4, 0.2],\n        [5.4, 3.9, 1.7, 0.4],\n        [4.6, 3.4, 1.4, 0.3],\n        [5. , 3.4, 1.5, 0.2],\n        [4.4, 2.9, 1.4, 0.2],\n        [4.9, 3.1, 1.5, 0.1],\n        [5.4, 3.7, 1.5, 0.2],\n        [4.8, 3.4, 1.6, 0.2],\n        [4.8, 3. , 1.4, 0.1],\n        [4.3, 3. , 1.1, 0.1],\n        [5.8, 4. , 1.2, 0.2],\n        [5.7, 4.4, 1.5, 0.4],\n        [5.4, 3.9, 1.3, 0.4],\n        [5.1, 3.5, 1.4, 0.3],\n        [5.7, 3.8, 1.7, 0.3],\n        [5.1, 3.8, 1.5, 0.3],\n        [5.4, 3.4, 1.7, 0.2],\n        [5.1, 3.7, 1.5, 0.4],\n        [4.6, 3.6, 1. , 0.2],\n        [5.1, 3.3, 1.7, 0.5],\n        [4.8, 3.4, 1.9, 0.2],\n        [5. , 3. , 1.6, 0.2],\n        [5. , 3.4, 1.6, 0.4],\n        [5.2, 3.5, 1.5, 0.2],\n        [5.2, 3.4, 1.4, 0.2],\n        [4.7, 3.2, 1.6, 0.2],\n        [4.8, 3.1, 1.6, 0.2],\n        [5.4, 3.4, 1.5, 0.4],\n        [5.2, 4.1, 1.5, 0.1],\n        [5.5, 4.2, 1.4, 0.2],\n        [4.9, 3.1, 1.5, 0.2],\n        [5. , 3.2, 1.2, 0.2],\n        [5.5, 3.5, 1.3, 0.2],\n        [4.9, 3.6, 1.4, 0.1],\n        [4.4, 3. , 1.3, 0.2],\n        [5.1, 3.4, 1.5, 0.2],\n        [5. , 3.5, 1.3, 0.3],\n        [4.5, 2.3, 1.3, 0.3],\n        [4.4, 3.2, 1.3, 0.2],\n        [5. , 3.5, 1.6, 0.6],\n        [5.1, 3.8, 1.9, 0.4],\n        [4.8, 3. , 1.4, 0.3],\n        [5.1, 3.8, 1.6, 0.2],\n        [4.6, 3.2, 1.4, 0.2],\n        [5.3, 3.7, 1.5, 0.2],\n        [5. , 3.3, 1.4, 0.2],\n        [7. , 3.2, 4.7, 1.4],\n        [6.4, 3.2, 4.5, 1.5],\n        [6.9, 3.1, 4.9, 1.5],\n        [5.5, 2.3, 4. , 1.3],\n        [6.5, 2.8, 4.6, 1.5],\n        [5.7, 2.8, 4.5, 1.3],\n        [6.3, 3.3, 4.7, 1.6],\n        [4.9, 2.4, 3.3, 1. ],\n        [6.6, 2.9, 4.6, 1.3],\n        [5.2, 2.7, 3.9, 1.4],\n        [5. , 2. , 3.5, 1. ],\n        [5.9, 3. , 4.2, 1.5],\n        [6. , 2.2, 4. , 1. ],\n        [6.1, 2.9, 4.7, 1.4],\n        [5.6, 2.9, 3.6, 1.3],\n        [6.7, 3.1, 4.4, 1.4],\n        [5.6, 3. , 4.5, 1.5],\n        [5.8, 2.7, 4.1, 1. ],\n        [6.2, 2.2, 4.5, 1.5],\n        [5.6, 2.5, 3.9, 1.1],\n        [5.9, 3.2, 4.8, 1.8],\n        [6.1, 2.8, 4. , 1.3],\n        [6.3, 2.5, 4.9, 1.5],\n        [6.1, 2.8, 4.7, 1.2],\n        [6.4, 2.9, 4.3, 1.3],\n        [6.6, 3. , 4.4, 1.4],\n        [6.8, 2.8, 4.8, 1.4],\n        [6.7, 3. , 5. , 1.7],\n        [6. , 2.9, 4.5, 1.5],\n        [5.7, 2.6, 3.5, 1. ],\n        [5.5, 2.4, 3.8, 1.1],\n        [5.5, 2.4, 3.7, 1. ],\n        [5.8, 2.7, 3.9, 1.2],\n        [6. , 2.7, 5.1, 1.6],\n        [5.4, 3. , 4.5, 1.5],\n        [6. , 3.4, 4.5, 1.6],\n        [6.7, 3.1, 4.7, 1.5],\n        [6.3, 2.3, 4.4, 1.3],\n        [5.6, 3. , 4.1, 1.3],\n        [5.5, 2.5, 4. , 1.3],\n        [5.5, 2.6, 4.4, 1.2],\n        [6.1, 3. , 4.6, 1.4],\n        [5.8, 2.6, 4. , 1.2],\n        [5. , 2.3, 3.3, 1. ],\n        [5.6, 2.7, 4.2, 1.3],\n        [5.7, 3. , 4.2, 1.2],\n        [5.7, 2.9, 4.2, 1.3],\n        [6.2, 2.9, 4.3, 1.3],\n        [5.1, 2.5, 3. , 1.1],\n        [5.7, 2.8, 4.1, 1.3],\n        [6.3, 3.3, 6. , 2.5],\n        [5.8, 2.7, 5.1, 1.9],\n        [7.1, 3. , 5.9, 2.1],\n        [6.3, 2.9, 5.6, 1.8],\n        [6.5, 3. , 5.8, 2.2],\n        [7.6, 3. , 6.6, 2.1],\n        [4.9, 2.5, 4.5, 1.7],\n        [7.3, 2.9, 6.3, 1.8],\n        [6.7, 2.5, 5.8, 1.8],\n        [7.2, 3.6, 6.1, 2.5],\n        [6.5, 3.2, 5.1, 2. ],\n        [6.4, 2.7, 5.3, 1.9],\n        [6.8, 3. , 5.5, 2.1],\n        [5.7, 2.5, 5. , 2. ],\n        [5.8, 2.8, 5.1, 2.4],\n        [6.4, 3.2, 5.3, 2.3],\n        [6.5, 3. , 5.5, 1.8],\n        [7.7, 3.8, 6.7, 2.2],\n        [7.7, 2.6, 6.9, 2.3],\n        [6. , 2.2, 5. , 1.5],\n        [6.9, 3.2, 5.7, 2.3],\n        [5.6, 2.8, 4.9, 2. ],\n        [7.7, 2.8, 6.7, 2. ],\n        [6.3, 2.7, 4.9, 1.8],\n        [6.7, 3.3, 5.7, 2.1],\n        [7.2, 3.2, 6. , 1.8],\n        [6.2, 2.8, 4.8, 1.8],\n        [6.1, 3. , 4.9, 1.8],\n        [6.4, 2.8, 5.6, 2.1],\n        [7.2, 3. , 5.8, 1.6],\n        [7.4, 2.8, 6.1, 1.9],\n        [7.9, 3.8, 6.4, 2. ],\n        [6.4, 2.8, 5.6, 2.2],\n        [6.3, 2.8, 5.1, 1.5],\n        [6.1, 2.6, 5.6, 1.4],\n        [7.7, 3. , 6.1, 2.3],\n        [6.3, 3.4, 5.6, 2.4],\n        [6.4, 3.1, 5.5, 1.8],\n        [6. , 3. , 4.8, 1.8],\n        [6.9, 3.1, 5.4, 2.1],\n        [6.7, 3.1, 5.6, 2.4],\n        [6.9, 3.1, 5.1, 2.3],\n        [5.8, 2.7, 5.1, 1.9],\n        [6.8, 3.2, 5.9, 2.3],\n        [6.7, 3.3, 5.7, 2.5],\n        [6.7, 3. , 5.2, 2.3],\n        [6.3, 2.5, 5. , 1.9],\n        [6.5, 3. , 5.2, 2. ],\n        [6.2, 3.4, 5.4, 2.3],\n        [5.9, 3. , 5.1, 1.8]]),\n 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n 'frame': None,\n 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n 'feature_names': ['sepal length (cm)',\n  'sepal width (cm)',\n  'petal length (cm)',\n  'petal width (cm)'],\n 'filename': 'iris.csv',\n 'data_module': 'sklearn.datasets.data'}"},"metadata":{}}]},{"cell_type":"code","source":"x = iris['data']\nx","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:16:06.524440Z","iopub.execute_input":"2024-08-24T05:16:06.524819Z","iopub.status.idle":"2024-08-24T05:16:06.536763Z","shell.execute_reply.started":"2024-08-24T05:16:06.524782Z","shell.execute_reply":"2024-08-24T05:16:06.535805Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.6, 1.4, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]])"},"metadata":{}}]},{"cell_type":"code","source":"y=iris['target']\ny\n#input columns","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:15:43.544710Z","iopub.execute_input":"2024-08-24T05:15:43.545586Z","iopub.status.idle":"2024-08-24T05:15:43.552399Z","shell.execute_reply.started":"2024-08-24T05:15:43.545545Z","shell.execute_reply":"2024-08-24T05:15:43.551301Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n\n#seperate training data and testing data","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:17:11.624597Z","iopub.execute_input":"2024-08-24T05:17:11.624958Z","iopub.status.idle":"2024-08-24T05:17:11.703801Z","shell.execute_reply.started":"2024-08-24T05:17:11.624926Z","shell.execute_reply":"2024-08-24T05:17:11.702974Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:17:15.434380Z","iopub.execute_input":"2024-08-24T05:17:15.435302Z","iopub.status.idle":"2024-08-24T05:17:15.440414Z","shell.execute_reply.started":"2024-08-24T05:17:15.435251Z","shell.execute_reply":"2024-08-24T05:17:15.439472Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(120, 4)\n(30, 4)\n(120,)\n(30,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\n#when want to train model sequentially then we use Sequential class\n#Dense class is used to establish fully connected network","metadata":{"execution":{"iopub.status.busy":"2024-08-24T09:48:00.415127Z","iopub.execute_input":"2024-08-24T09:48:00.415756Z","iopub.status.idle":"2024-08-24T09:48:00.422172Z","shell.execute_reply.started":"2024-08-24T09:48:00.415719Z","shell.execute_reply":"2024-08-24T09:48:00.421328Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(8, activation='relu', input_dim=4))\nmodel.add(Dense(6, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:47:11.205024Z","iopub.execute_input":"2024-08-24T05:47:11.205738Z","iopub.status.idle":"2024-08-24T05:47:11.241727Z","shell.execute_reply.started":"2024-08-24T05:47:11.205694Z","shell.execute_reply":"2024-08-24T05:47:11.240800Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()\n\n#see model summary","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:47:11.865374Z","iopub.execute_input":"2024-08-24T05:47:11.866198Z","iopub.status.idle":"2024-08-24T05:47:11.883457Z","shell.execute_reply.started":"2024-08-24T05:47:11.866159Z","shell.execute_reply":"2024-08-24T05:47:11.882605Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_8\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m54\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate = 0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n# my traget label is not one hot encoded so that I use sparse_categorical_carossentropy","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:47:12.712051Z","iopub.execute_input":"2024-08-24T05:47:12.712871Z","iopub.status.idle":"2024-08-24T05:47:12.721154Z","shell.execute_reply.started":"2024-08-24T05:47:12.712826Z","shell.execute_reply":"2024-08-24T05:47:12.720387Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"history=model.fit(x_train,y_train,epochs=50,batch_size = 16, validation_split=0.2)\n\n#model training and store model in history","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:47:13.534186Z","iopub.execute_input":"2024-08-24T05:47:13.534574Z","iopub.status.idle":"2024-08-24T05:47:18.276523Z","shell.execute_reply.started":"2024-08-24T05:47:13.534537Z","shell.execute_reply":"2024-08-24T05:47:18.275727Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.3707 - loss: 1.2982 - val_accuracy: 0.4167 - val_loss: 1.0760\nEpoch 2/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3296 - loss: 1.2893 - val_accuracy: 0.4167 - val_loss: 1.0375\nEpoch 3/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2537 - loss: 1.3277 - val_accuracy: 0.4167 - val_loss: 1.0038\nEpoch 4/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2899 - loss: 1.1770 - val_accuracy: 0.4167 - val_loss: 0.9750\nEpoch 5/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3146 - loss: 1.1234 - val_accuracy: 0.4167 - val_loss: 0.9509\nEpoch 6/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3187 - loss: 1.0753 - val_accuracy: 0.4167 - val_loss: 0.9319\nEpoch 7/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3760 - loss: 0.9883 - val_accuracy: 0.4167 - val_loss: 0.9201\nEpoch 8/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3115 - loss: 1.0115 - val_accuracy: 0.4167 - val_loss: 0.9089\nEpoch 9/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2442 - loss: 1.0514 - val_accuracy: 0.4167 - val_loss: 0.8990\nEpoch 10/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2763 - loss: 0.9981 - val_accuracy: 0.4167 - val_loss: 0.8880\nEpoch 11/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3287 - loss: 0.9709 - val_accuracy: 0.6667 - val_loss: 0.8772\nEpoch 12/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6140 - loss: 0.9366 - val_accuracy: 0.7500 - val_loss: 0.8657\nEpoch 13/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6330 - loss: 0.9599 - val_accuracy: 0.8333 - val_loss: 0.8544\nEpoch 14/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6167 - loss: 0.9362 - val_accuracy: 0.8333 - val_loss: 0.8425\nEpoch 15/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6280 - loss: 0.9293 - val_accuracy: 0.8333 - val_loss: 0.8306\nEpoch 16/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6731 - loss: 0.8856 - val_accuracy: 0.8333 - val_loss: 0.8185\nEpoch 17/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 0.9144 - val_accuracy: 0.8333 - val_loss: 0.8074\nEpoch 18/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5900 - loss: 0.8899 - val_accuracy: 0.8333 - val_loss: 0.7959\nEpoch 19/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6732 - loss: 0.8386 - val_accuracy: 0.8333 - val_loss: 0.7823\nEpoch 20/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6287 - loss: 0.8352 - val_accuracy: 0.8333 - val_loss: 0.7694\nEpoch 21/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6509 - loss: 0.8103 - val_accuracy: 0.8333 - val_loss: 0.7558\nEpoch 22/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6088 - loss: 0.8285 - val_accuracy: 0.8333 - val_loss: 0.7429\nEpoch 23/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6260 - loss: 0.8216 - val_accuracy: 0.8333 - val_loss: 0.7296\nEpoch 24/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6406 - loss: 0.7919 - val_accuracy: 0.8333 - val_loss: 0.7167\nEpoch 25/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6629 - loss: 0.7812 - val_accuracy: 0.8333 - val_loss: 0.7030\nEpoch 26/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6167 - loss: 0.7784 - val_accuracy: 0.8333 - val_loss: 0.6906\nEpoch 27/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6545 - loss: 0.7475 - val_accuracy: 0.8333 - val_loss: 0.6784\nEpoch 28/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6710 - loss: 0.7435 - val_accuracy: 0.8333 - val_loss: 0.6658\nEpoch 29/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5871 - loss: 0.7614 - val_accuracy: 0.8750 - val_loss: 0.6551\nEpoch 30/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6760 - loss: 0.7131 - val_accuracy: 0.8750 - val_loss: 0.6417\nEpoch 31/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6445 - loss: 0.7146 - val_accuracy: 0.8750 - val_loss: 0.6304\nEpoch 32/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6125 - loss: 0.7171 - val_accuracy: 0.8750 - val_loss: 0.6202\nEpoch 33/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6991 - loss: 0.6859 - val_accuracy: 0.8750 - val_loss: 0.6079\nEpoch 34/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7189 - loss: 0.6940 - val_accuracy: 0.8750 - val_loss: 0.5980\nEpoch 35/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7271 - loss: 0.6672 - val_accuracy: 0.8750 - val_loss: 0.5874\nEpoch 36/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.6520 - val_accuracy: 0.8750 - val_loss: 0.5766\nEpoch 37/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7484 - loss: 0.6693 - val_accuracy: 0.8750 - val_loss: 0.5674\nEpoch 38/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8338 - loss: 0.6194 - val_accuracy: 0.8750 - val_loss: 0.5570\nEpoch 39/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7607 - loss: 0.6331 - val_accuracy: 0.9583 - val_loss: 0.5487\nEpoch 40/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8362 - loss: 0.6147 - val_accuracy: 0.9583 - val_loss: 0.5375\nEpoch 41/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8385 - loss: 0.5933 - val_accuracy: 0.9583 - val_loss: 0.5285\nEpoch 42/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7641 - loss: 0.6112 - val_accuracy: 0.9583 - val_loss: 0.5209\nEpoch 43/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.5701 - val_accuracy: 0.9583 - val_loss: 0.5117\nEpoch 44/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8772 - loss: 0.5761 - val_accuracy: 0.9583 - val_loss: 0.5031\nEpoch 45/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8766 - loss: 0.5514 - val_accuracy: 0.9583 - val_loss: 0.4920\nEpoch 46/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8549 - loss: 0.5632 - val_accuracy: 0.9583 - val_loss: 0.4864\nEpoch 47/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.5437 - val_accuracy: 0.9583 - val_loss: 0.4776\nEpoch 48/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5307 - val_accuracy: 0.9583 - val_loss: 0.4699\nEpoch 49/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.5428 - val_accuracy: 0.9583 - val_loss: 0.4618\nEpoch 50/50\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8881 - loss: 0.5389 - val_accuracy: 0.9583 - val_loss: 0.4567\n","output_type":"stream"}]},{"cell_type":"code","source":"y_predict=model.predict(x_test)\ny_predict\n\n#model testing","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:47:50.479690Z","iopub.execute_input":"2024-08-24T05:47:50.480622Z","iopub.status.idle":"2024-08-24T05:47:50.693171Z","shell.execute_reply.started":"2024-08-24T05:47:50.480578Z","shell.execute_reply":"2024-08-24T05:47:50.692285Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"array([[0.037067  , 0.29631764, 0.66661537],\n       [0.08197067, 0.4568053 , 0.46122414],\n       [0.70009696, 0.21160768, 0.08829538],\n       [0.02927739, 0.29851007, 0.67221254],\n       [0.05414385, 0.40039203, 0.5454642 ],\n       [0.08182162, 0.46380627, 0.45437214],\n       [0.724522  , 0.19626713, 0.0792108 ],\n       [0.7935461 , 0.15297239, 0.05348155],\n       [0.10064615, 0.46586555, 0.43348828],\n       [0.07658035, 0.48460442, 0.43881518],\n       [0.13420014, 0.49049935, 0.3753005 ],\n       [0.04293352, 0.3362556 , 0.6208109 ],\n       [0.02415861, 0.3004557 , 0.6753857 ],\n       [0.10844847, 0.46430346, 0.42724806],\n       [0.08375046, 0.49016234, 0.42608723],\n       [0.7535415 , 0.17794782, 0.0685107 ],\n       [0.17953767, 0.4716131 , 0.34884924],\n       [0.0145287 , 0.3312519 , 0.65421945],\n       [0.01933306, 0.37692726, 0.6037397 ],\n       [0.03370807, 0.43746784, 0.5288241 ],\n       [0.11302123, 0.44978428, 0.43719447],\n       [0.11573584, 0.49492306, 0.3893411 ],\n       [0.73639435, 0.18847556, 0.07513009],\n       [0.69868577, 0.21257   , 0.08874425],\n       [0.752589  , 0.1785875 , 0.06882355],\n       [0.02227131, 0.38157305, 0.5961556 ],\n       [0.7631718 , 0.17200169, 0.06482649],\n       [0.11803571, 0.43420872, 0.44775555],\n       [0.7511125 , 0.17951821, 0.06936932],\n       [0.03899674, 0.34116375, 0.61983955]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:48:06.771696Z","iopub.execute_input":"2024-08-24T05:48:06.772352Z","iopub.status.idle":"2024-08-24T05:48:06.778495Z","shell.execute_reply.started":"2024-08-24T05:48:06.772311Z","shell.execute_reply":"2024-08-24T05:48:06.777563Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"array([2, 1, 0, 2, 2, 1, 0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1,\n       0, 0, 0, 2, 0, 1, 0, 2])"},"metadata":{}}]},{"cell_type":"markdown","source":"# To improve performance,\n1. Hyperparameter Tuning:\n* Learning Rate: Experiment with slightly lower or higher learning rates (e.g., 0.0005 or 0.005).\n* Batch Size: Try different batch sizes (e.g., 8, 32) to see how they impact training stability and convergence.\n\n2. Increase Model Complexity:\n* Add More Layers: Introduce additional hidden layers or increase the number of neurons in existing layers.\n\n3. Regularization Techniques:\n* Dropout: Add dropout layers to prevent overfitting.\n* L2 Regularization: Apply L2 regularization to the dense layers.\n\n4. Learning Rate Schedulers:\n* Reduce Learning Rate on Plateau: Automatically reduce the learning rate when a metric has stopped improving.\n\n5. Data Augmentation:\n* Synthetic Data Generation: Although not typically needed for small datasets like Iris, you could augment the data using slight variations if the dataset were larger or more complex.\n\n6. Cross-Validation:\n* K-Fold Cross-Validation: Use cross-validation instead of a single train-validation split to better assess model performance.\n\n7. Early Stopping:\n* Stop Training Early: Use early stopping to halt training when validation performance no longer improves.\n\n8. Feature Engineering:\n* Standardization: Ensure that input features are standardized (mean=0, std=1) to help the model converge faster.\n\n9. Optimize the Network Architecture:\n* Experiment with Different Activations: Try other activation functions like LeakyReLU or ELU in hidden layers.\n\n10. Use a Different Optimizer:\n* Try Alternative Optimizers: Experiment with optimizers like RMSprop or Adam with different settings.\n","metadata":{}},{"cell_type":"markdown","source":"# Don't run below shell it's just interpretatio of how you can do above task","metadata":{}},{"cell_type":"markdown","source":"# 2","metadata":{}},{"cell_type":"code","source":"model.add(Dense(10, activation='relu'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3","metadata":{}},{"cell_type":"code","source":"#dropout\n\nfrom tensorflow.keras.layers import Dropout\nmodel.add(Dropout(0.3))  # 30% dropout rate\n\n#L2-regularization\n\nfrom tensorflow.keras.regularizers import l2\nmodel.add(Dense(8, activation='relu', kernel_regularizer=l2(0.01)))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\nmodel.fit(x_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[lr_scheduler])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nkfold = KFold(n_splits=5, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nmodel.fit(x_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import LeakyReLU\nmodel.add(Dense(8))\nmodel.add(LeakyReLU(alpha=0.1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# B: Image Data\n* Neural Network implementation on mnist dataset (Image as an input)\n* Task 1: Creating First Artificial Neural Network (ANN) using Keras and Tensorflow.\n> Dataset: MNIST\n* Task 2: Improve the performance of Artificial Neural Network.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nmnist = load_digits()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T09:52:58.347966Z","iopub.execute_input":"2024-08-24T09:52:58.348389Z","iopub.status.idle":"2024-08-24T09:52:58.483286Z","shell.execute_reply.started":"2024-08-24T09:52:58.348348Z","shell.execute_reply":"2024-08-24T09:52:58.482342Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"mnist","metadata":{"execution":{"iopub.status.busy":"2024-08-24T09:53:06.585094Z","iopub.execute_input":"2024-08-24T09:53:06.585500Z","iopub.status.idle":"2024-08-24T09:53:06.600256Z","shell.execute_reply.started":"2024-08-24T09:53:06.585463Z","shell.execute_reply":"2024-08-24T09:53:06.599360Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n        ...,\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n 'target': array([0, 1, 2, ..., 8, 9, 8]),\n 'frame': None,\n 'feature_names': ['pixel_0_0',\n  'pixel_0_1',\n  'pixel_0_2',\n  'pixel_0_3',\n  'pixel_0_4',\n  'pixel_0_5',\n  'pixel_0_6',\n  'pixel_0_7',\n  'pixel_1_0',\n  'pixel_1_1',\n  'pixel_1_2',\n  'pixel_1_3',\n  'pixel_1_4',\n  'pixel_1_5',\n  'pixel_1_6',\n  'pixel_1_7',\n  'pixel_2_0',\n  'pixel_2_1',\n  'pixel_2_2',\n  'pixel_2_3',\n  'pixel_2_4',\n  'pixel_2_5',\n  'pixel_2_6',\n  'pixel_2_7',\n  'pixel_3_0',\n  'pixel_3_1',\n  'pixel_3_2',\n  'pixel_3_3',\n  'pixel_3_4',\n  'pixel_3_5',\n  'pixel_3_6',\n  'pixel_3_7',\n  'pixel_4_0',\n  'pixel_4_1',\n  'pixel_4_2',\n  'pixel_4_3',\n  'pixel_4_4',\n  'pixel_4_5',\n  'pixel_4_6',\n  'pixel_4_7',\n  'pixel_5_0',\n  'pixel_5_1',\n  'pixel_5_2',\n  'pixel_5_3',\n  'pixel_5_4',\n  'pixel_5_5',\n  'pixel_5_6',\n  'pixel_5_7',\n  'pixel_6_0',\n  'pixel_6_1',\n  'pixel_6_2',\n  'pixel_6_3',\n  'pixel_6_4',\n  'pixel_6_5',\n  'pixel_6_6',\n  'pixel_6_7',\n  'pixel_7_0',\n  'pixel_7_1',\n  'pixel_7_2',\n  'pixel_7_3',\n  'pixel_7_4',\n  'pixel_7_5',\n  'pixel_7_6',\n  'pixel_7_7'],\n 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n         ...,\n         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n \n        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n         ...,\n         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n \n        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n         ...,\n         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n \n        ...,\n \n        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n         ...,\n         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n \n        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n         ...,\n         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n \n        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n         ...,\n         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"},"metadata":{}}]},{"cell_type":"code","source":"x = mnist['data']\nx","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:09:53.424957Z","iopub.execute_input":"2024-08-24T10:09:53.425437Z","iopub.status.idle":"2024-08-24T10:09:53.433075Z","shell.execute_reply.started":"2024-08-24T10:09:53.425396Z","shell.execute_reply":"2024-08-24T10:09:53.432216Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n       ...,\n       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"},"metadata":{}}]},{"cell_type":"code","source":"y = mnist['target']\ny","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:10:10.245430Z","iopub.execute_input":"2024-08-24T10:10:10.245796Z","iopub.status.idle":"2024-08-24T10:10:10.252408Z","shell.execute_reply.started":"2024-08-24T10:10:10.245761Z","shell.execute_reply":"2024-08-24T10:10:10.251435Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 2, ..., 8, 9, 8])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test =  train_test_split(x,y,test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:48:40.025132Z","iopub.execute_input":"2024-08-24T10:48:40.026083Z","iopub.status.idle":"2024-08-24T10:48:40.032146Z","shell.execute_reply.started":"2024-08-24T10:48:40.026042Z","shell.execute_reply":"2024-08-24T10:48:40.031305Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:48:42.104681Z","iopub.execute_input":"2024-08-24T10:48:42.105446Z","iopub.status.idle":"2024-08-24T10:48:42.110749Z","shell.execute_reply.started":"2024-08-24T10:48:42.105403Z","shell.execute_reply":"2024-08-24T10:48:42.109757Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"(1437, 64)\n(1437,)\n(360, 64)\n(360,)\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train = x_train / 255.0\nx_test = x_test / 255.0","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:48:44.424706Z","iopub.execute_input":"2024-08-24T10:48:44.425463Z","iopub.status.idle":"2024-08-24T10:48:44.429854Z","shell.execute_reply.started":"2024-08-24T10:48:44.425423Z","shell.execute_reply":"2024-08-24T10:48:44.428944Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"x_train[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:48:31.535372Z","iopub.execute_input":"2024-08-24T10:48:31.535806Z","iopub.status.idle":"2024-08-24T10:48:31.542243Z","shell.execute_reply.started":"2024-08-24T10:48:31.535769Z","shell.execute_reply":"2024-08-24T10:48:31.541348Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(64,)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:42:48.804549Z","iopub.execute_input":"2024-08-24T10:42:48.805442Z","iopub.status.idle":"2024-08-24T10:42:48.809483Z","shell.execute_reply.started":"2024-08-24T10:42:48.805402Z","shell.execute_reply":"2024-08-24T10:42:48.808431Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Flatten(input_shape=(64,)))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:52:12.670393Z","iopub.execute_input":"2024-08-24T10:52:12.670782Z","iopub.status.idle":"2024-08-24T10:52:12.716263Z","shell.execute_reply.started":"2024-08-24T10:52:12.670748Z","shell.execute_reply":"2024-08-24T10:52:12.715499Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:52:13.284847Z","iopub.execute_input":"2024-08-24T10:52:13.285264Z","iopub.status.idle":"2024-08-24T10:52:13.307231Z","shell.execute_reply.started":"2024-08-24T10:52:13.285224Z","shell.execute_reply":"2024-08-24T10:52:13.306236Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,570\u001b[0m (25.66 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,570</span> (25.66 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,570\u001b[0m (25.66 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,570</span> (25.66 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:52:14.384364Z","iopub.execute_input":"2024-08-24T10:52:14.384762Z","iopub.status.idle":"2024-08-24T10:52:14.394188Z","shell.execute_reply.started":"2024-08-24T10:52:14.384725Z","shell.execute_reply":"2024-08-24T10:52:14.393364Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:52:40.285110Z","iopub.execute_input":"2024-08-24T10:52:40.285527Z","iopub.status.idle":"2024-08-24T10:52:45.237225Z","shell.execute_reply.started":"2024-08-24T10:52:40.285485Z","shell.execute_reply":"2024-08-24T10:52:45.236414Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.3128 - val_accuracy: 0.8785 - val_loss: 0.3908\nEpoch 2/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.2734 - val_accuracy: 0.8958 - val_loss: 0.3661\nEpoch 3/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2679 - val_accuracy: 0.8993 - val_loss: 0.3524\nEpoch 4/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.2528 - val_accuracy: 0.9028 - val_loss: 0.3485\nEpoch 5/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.2252 - val_accuracy: 0.8993 - val_loss: 0.3408\nEpoch 6/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2299 - val_accuracy: 0.9028 - val_loss: 0.3294\nEpoch 7/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.2403 - val_accuracy: 0.8958 - val_loss: 0.3182\nEpoch 8/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.2259 - val_accuracy: 0.8993 - val_loss: 0.3116\nEpoch 9/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.2041 - val_accuracy: 0.9028 - val_loss: 0.3130\nEpoch 10/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1839 - val_accuracy: 0.9132 - val_loss: 0.3116\nEpoch 11/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.2083 - val_accuracy: 0.9201 - val_loss: 0.3054\nEpoch 12/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1845 - val_accuracy: 0.9028 - val_loss: 0.2950\nEpoch 13/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1676 - val_accuracy: 0.9201 - val_loss: 0.2817\nEpoch 14/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1725 - val_accuracy: 0.9236 - val_loss: 0.2764\nEpoch 15/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9553 - loss: 0.1651 - val_accuracy: 0.9236 - val_loss: 0.2678\nEpoch 16/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1670 - val_accuracy: 0.9167 - val_loss: 0.2718\nEpoch 17/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1565 - val_accuracy: 0.9201 - val_loss: 0.2641\nEpoch 18/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1606 - val_accuracy: 0.9271 - val_loss: 0.2582\nEpoch 19/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9636 - loss: 0.1432 - val_accuracy: 0.9167 - val_loss: 0.2513\nEpoch 20/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.1427 - val_accuracy: 0.9167 - val_loss: 0.2556\nEpoch 21/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1457 - val_accuracy: 0.9236 - val_loss: 0.2459\nEpoch 22/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1519 - val_accuracy: 0.9236 - val_loss: 0.2482\nEpoch 23/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1552 - val_accuracy: 0.9306 - val_loss: 0.2459\nEpoch 24/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1391 - val_accuracy: 0.9306 - val_loss: 0.2295\nEpoch 25/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.1205 - val_accuracy: 0.9271 - val_loss: 0.2342\nEpoch 26/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1181 - val_accuracy: 0.9340 - val_loss: 0.2274\nEpoch 27/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.1303 - val_accuracy: 0.9306 - val_loss: 0.2367\nEpoch 28/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.1191 - val_accuracy: 0.9306 - val_loss: 0.2363\nEpoch 29/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.1124 - val_accuracy: 0.9306 - val_loss: 0.2254\nEpoch 30/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.1216 - val_accuracy: 0.9375 - val_loss: 0.2199\nEpoch 31/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.1157 - val_accuracy: 0.9340 - val_loss: 0.2145\nEpoch 32/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.1150 - val_accuracy: 0.9306 - val_loss: 0.2145\nEpoch 33/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0984 - val_accuracy: 0.9410 - val_loss: 0.2152\nEpoch 34/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.1060 - val_accuracy: 0.9375 - val_loss: 0.2262\nEpoch 35/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.1028 - val_accuracy: 0.9375 - val_loss: 0.2248\nEpoch 36/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.1079 - val_accuracy: 0.9410 - val_loss: 0.2238\nEpoch 37/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0987 - val_accuracy: 0.9375 - val_loss: 0.2068\nEpoch 38/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0960 - val_accuracy: 0.9340 - val_loss: 0.2022\nEpoch 39/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0904 - val_accuracy: 0.9340 - val_loss: 0.2084\nEpoch 40/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0851 - val_accuracy: 0.9444 - val_loss: 0.2108\nEpoch 41/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.1058 - val_accuracy: 0.9375 - val_loss: 0.2019\nEpoch 42/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.1042 - val_accuracy: 0.9410 - val_loss: 0.2073\nEpoch 43/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0788 - val_accuracy: 0.9375 - val_loss: 0.1953\nEpoch 44/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0910 - val_accuracy: 0.9340 - val_loss: 0.1974\nEpoch 45/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0749 - val_accuracy: 0.9444 - val_loss: 0.1920\nEpoch 46/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0823 - val_accuracy: 0.9375 - val_loss: 0.2002\nEpoch 47/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0809 - val_accuracy: 0.9444 - val_loss: 0.2080\nEpoch 48/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0839 - val_accuracy: 0.9375 - val_loss: 0.1920\nEpoch 49/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0683 - val_accuracy: 0.9444 - val_loss: 0.2001\nEpoch 50/50\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0865 - val_accuracy: 0.9410 - val_loss: 0.1978\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* We can use same techniques as before for improve performance","metadata":{}}]}