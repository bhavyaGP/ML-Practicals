{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3866368,"sourceType":"datasetVersion","datasetId":849073}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T06:56:30.763047Z","iopub.execute_input":"2024-10-21T06:56:30.763841Z","iopub.status.idle":"2024-10-21T06:56:30.769657Z","shell.execute_reply.started":"2024-10-21T06:56:30.763799Z","shell.execute_reply":"2024-10-21T06:56:30.768638Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Task 2: CNN on Custom Fruit Classification Dataset (Without Preprocessing)","metadata":{}},{"cell_type":"code","source":"# Load the dataset paths (assuming train/ and test/ folders are organized)\ntrain_dir = '/kaggle/input/fruit-recognition/train/train'\ntest_dir = '/kaggle/input/fruit-recognition/test/test'\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:07:49.102454Z","iopub.execute_input":"2024-10-21T07:07:49.102870Z","iopub.status.idle":"2024-10-21T07:07:49.107968Z","shell.execute_reply.started":"2024-10-21T07:07:49.102830Z","shell.execute_reply":"2024-10-21T07:07:49.106799Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Create ImageDataGenerator for loading images without preprocessing\ntrain_gen = ImageDataGenerator()\ntest_gen = ImageDataGenerator()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:07:49.622302Z","iopub.execute_input":"2024-10-21T07:07:49.622731Z","iopub.status.idle":"2024-10-21T07:07:49.627304Z","shell.execute_reply.started":"2024-10-21T07:07:49.622690Z","shell.execute_reply":"2024-10-21T07:07:49.626297Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Load the training and testing data\ntrain_data = train_gen.flow_from_directory(train_dir, target_size=(100, 100), batch_size=32, class_mode='categorical')\ntest_data = test_gen.flow_from_directory(test_dir, target_size=(100, 100), batch_size=32, class_mode='categorical')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:07:50.582253Z","iopub.execute_input":"2024-10-21T07:07:50.582656Z","iopub.status.idle":"2024-10-21T07:07:53.558257Z","shell.execute_reply.started":"2024-10-21T07:07:50.582620Z","shell.execute_reply":"2024-10-21T07:07:53.557493Z"}},"outputs":[{"name":"stdout","text":"Found 16854 images belonging to 33 classes.\nFound 0 images belonging to 0 classes.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Build the CNN model\nmodel_fruit = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(33, activation='softmax')\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T06:56:42.742690Z","iopub.execute_input":"2024-10-21T06:56:42.743110Z","iopub.status.idle":"2024-10-21T06:56:42.789969Z","shell.execute_reply.started":"2024-10-21T06:56:42.743069Z","shell.execute_reply":"2024-10-21T06:56:42.788946Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Compile the model\nmodel_fruit.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T06:56:42.962740Z","iopub.execute_input":"2024-10-21T06:56:42.963437Z","iopub.status.idle":"2024-10-21T06:56:42.971907Z","shell.execute_reply.started":"2024-10-21T06:56:42.963399Z","shell.execute_reply":"2024-10-21T06:56:42.970868Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Train the model\nmodel_fruit.fit(train_data, epochs=10)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T06:59:07.483507Z","iopub.execute_input":"2024-10-21T06:59:07.483917Z","iopub.status.idle":"2024-10-21T07:02:11.715415Z","shell.execute_reply.started":"2024-10-21T06:59:07.483881Z","shell.execute_reply":"2024-10-21T07:02:11.714360Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - accuracy: 0.9166 - loss: 0.2825\nEpoch 2/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.9515 - loss: 0.1666\nEpoch 3/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - accuracy: 0.9451 - loss: 0.2091\nEpoch 4/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - accuracy: 0.9432 - loss: 0.2405\nEpoch 5/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.9505 - loss: 0.2351\nEpoch 6/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.9665 - loss: 0.1243\nEpoch 7/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.9744 - loss: 0.0998\nEpoch 8/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.9750 - loss: 0.1001\nEpoch 9/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - accuracy: 0.9716 - loss: 0.1272\nEpoch 10/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - accuracy: 0.9819 - loss: 0.0689\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b89657f6020>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Evaluate the model\n# fruit_loss, fruit_acc = model_fruit.evaluate(test_data)\n# print(f'Fruit Dataset Test Accuracy (Without Preprocessing): {fruit_acc}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:05:48.703064Z","iopub.execute_input":"2024-10-21T07:05:48.703534Z","iopub.status.idle":"2024-10-21T07:05:48.708000Z","shell.execute_reply.started":"2024-10-21T07:05:48.703494Z","shell.execute_reply":"2024-10-21T07:05:48.706781Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Task 3: CNN on Custom Fruit Classification Dataset (With Preprocessing)\n","metadata":{}},{"cell_type":"code","source":"# Use ImageDataGenerator with preprocessing (rescale pixel values)\ntrain_gen = ImageDataGenerator(rescale=1.0/255.0, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\ntest_gen = ImageDataGenerator(rescale=1.0/255.0)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:08:12.552384Z","iopub.execute_input":"2024-10-21T07:08:12.552794Z","iopub.status.idle":"2024-10-21T07:08:12.557871Z","shell.execute_reply.started":"2024-10-21T07:08:12.552754Z","shell.execute_reply":"2024-10-21T07:08:12.556712Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Load the training and testing data with preprocessing\ntrain_data = train_gen.flow_from_directory(train_dir, target_size=(100, 100), batch_size=32, class_mode='categorical')\ntest_data = test_gen.flow_from_directory(test_dir, target_size=(100, 100), batch_size=32, class_mode='categorical')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:08:14.057392Z","iopub.execute_input":"2024-10-21T07:08:14.057809Z","iopub.status.idle":"2024-10-21T07:08:14.782936Z","shell.execute_reply.started":"2024-10-21T07:08:14.057766Z","shell.execute_reply":"2024-10-21T07:08:14.781868Z"}},"outputs":[{"name":"stdout","text":"Found 16854 images belonging to 33 classes.\nFound 0 images belonging to 0 classes.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Build the CNN model (same as before)\nmodel_fruit_pre = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(33, activation='softmax')\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:08:16.102301Z","iopub.execute_input":"2024-10-21T07:08:16.102776Z","iopub.status.idle":"2024-10-21T07:08:16.157781Z","shell.execute_reply.started":"2024-10-21T07:08:16.102733Z","shell.execute_reply":"2024-10-21T07:08:16.156675Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Compile the model\nmodel_fruit_pre.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:08:17.172350Z","iopub.execute_input":"2024-10-21T07:08:17.172746Z","iopub.status.idle":"2024-10-21T07:08:17.182337Z","shell.execute_reply.started":"2024-10-21T07:08:17.172708Z","shell.execute_reply":"2024-10-21T07:08:17.181378Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Train the model with preprocessed data\nmodel_fruit_pre.fit(train_data, epochs=10)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:08:32.922587Z","iopub.execute_input":"2024-10-21T07:08:32.923639Z","iopub.status.idle":"2024-10-21T07:19:01.009121Z","shell.execute_reply.started":"2024-10-21T07:08:32.923583Z","shell.execute_reply":"2024-10-21T07:19:01.008113Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 124ms/step - accuracy: 0.5263 - loss: 1.5432\nEpoch 2/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 116ms/step - accuracy: 0.8952 - loss: 0.3060\nEpoch 3/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 118ms/step - accuracy: 0.9356 - loss: 0.1984\nEpoch 4/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 119ms/step - accuracy: 0.9439 - loss: 0.1559\nEpoch 5/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 117ms/step - accuracy: 0.9588 - loss: 0.1188\nEpoch 6/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 117ms/step - accuracy: 0.9596 - loss: 0.1192\nEpoch 7/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 118ms/step - accuracy: 0.9648 - loss: 0.1035\nEpoch 8/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 116ms/step - accuracy: 0.9624 - loss: 0.1088\nEpoch 9/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 117ms/step - accuracy: 0.9679 - loss: 0.0911\nEpoch 10/10\n\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 116ms/step - accuracy: 0.9745 - loss: 0.0773\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b859440b160>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# Evaluate the model\n# fruit_pre_loss, fruit_pre_acc = model_fruit_pre.evaluate(test_data)\n# print(f'Fruit Dataset Test Accuracy (With Preprocessing): {fruit_pre_acc}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T06:58:45.255468Z","iopub.status.idle":"2024-10-21T06:58:45.255985Z","shell.execute_reply.started":"2024-10-21T06:58:45.255699Z","shell.execute_reply":"2024-10-21T06:58:45.255725Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 4: Measure Differences and Analyze Results","metadata":{}},{"cell_type":"code","source":"\n\n# Analyze and write down your observations\nobservations = \"\"\"\n1. **MNIST Dataset**: Achieves high accuracy because the dataset is simple and well-structured.\n2. **Fruit Dataset (Without Preprocessing)**: Lower accuracy due to unnormalized pixel values and no data augmentation, which makes it harder for the model to generalize.\n3. **Fruit Dataset (With Preprocessing)**: Higher accuracy due to pixel normalization and data augmentation (rotation, zoom, flip), which helps the model generalize better to unseen data.\n4. **Impact of Preprocessing**: Preprocessing techniques such as normalization and augmentation significantly improve the model's performance by reducing overfitting and handling variations in the dataset.\n\"\"\"\nprint(observations)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T07:24:31.968329Z","iopub.execute_input":"2024-10-21T07:24:31.968728Z","iopub.status.idle":"2024-10-21T07:24:31.974854Z","shell.execute_reply.started":"2024-10-21T07:24:31.968692Z","shell.execute_reply":"2024-10-21T07:24:31.973764Z"}},"outputs":[{"name":"stdout","text":"\n1. **MNIST Dataset**: Achieves high accuracy because the dataset is simple and well-structured.\n2. **Fruit Dataset (Without Preprocessing)**: Lower accuracy due to unnormalized pixel values and no data augmentation, which makes it harder for the model to generalize.\n3. **Fruit Dataset (With Preprocessing)**: Higher accuracy due to pixel normalization and data augmentation (rotation, zoom, flip), which helps the model generalize better to unseen data.\n4. **Impact of Preprocessing**: Preprocessing techniques such as normalization and augmentation significantly improve the model's performance by reducing overfitting and handling variations in the dataset.\n\n","output_type":"stream"}],"execution_count":38}]}